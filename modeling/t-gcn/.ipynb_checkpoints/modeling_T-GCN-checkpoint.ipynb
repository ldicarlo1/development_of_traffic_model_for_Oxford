{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stunning-kitchen",
   "metadata": {},
   "source": [
    "# Modeling of Peartree Roundabout Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory to parent folder to access all folders\n",
    "import os\n",
    "path = os.path.dirname(os.getcwd())\n",
    "os.chdir(path)\n",
    "from data_preprocessing.classes.load_traffic_data import Import_Traffic_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import keras\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense,concatenate\n",
    "from stellargraph import StellarGraph, StellarDiGraph\n",
    "import stellargraph as sg\n",
    "from datetime import datetime\n",
    "from stellargraph.layer import GCN_LSTM\n",
    "import pmdarima as pm\n",
    "from pmdarima.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from classes import model_performance,preprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-relay",
   "metadata": {},
   "source": [
    "## Load Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peartree roundabout bbox and datetimes of interest\n",
    "top=51.798433\n",
    "bottom=51.791451\n",
    "right=-1.281979\n",
    "left=-1.289524\n",
    "datetime_start=datetime(2021,6,23,0,0)\n",
    "datetime_end=datetime(2021,7,13,10,50)\n",
    "\n",
    "# load in traffic data\n",
    "traffic_data,time = Import_Traffic_Data(top,bottom,right,left).load_traffic_data(datetime_start,datetime_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed capped by speed limit\n",
    "sp = traffic_data[:,:,5]\n",
    "\n",
    "# coordinates\n",
    "lons = traffic_data[0,:,4]\n",
    "lats = traffic_data[0,:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-vegetarian",
   "metadata": {},
   "source": [
    "## Load WX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in 5min wx data from csv\n",
    "wx_df = pd.read_csv(\"data_collection/data/wx_data/oxfordcity_wx_variables_5min_intervals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect variables of significance\n",
    "wx_vars = wx_df[['precipitationIntensity','temperature','humidity','weatherCode']].T\n",
    "\n",
    "for i in range(4):\n",
    "    wx_vars.iloc[i] = (wx_vars.iloc[i] - wx_vars.iloc[i].min())/(wx_vars.iloc[i].max() - wx_vars.iloc[i].min())\n",
    "    \n",
    "wx_vars = wx_vars.values\n",
    "#scaler = MinMaxScaler()\n",
    "#wx_vars = scaler.fit_transform(wx_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-plasma",
   "metadata": {},
   "source": [
    "## Create Road-Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in csv of node connections\n",
    "connections = pd.read_csv(f\"{path}/data_preprocessing/peartree_roundabout.csv\")\n",
    "connections.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert feeding roads to integers\n",
    "for i in range(len(connections)):\n",
    "#for i in range(4):\n",
    "    try:\n",
    "        connections.feeding_roads.iloc[i] = ast.literal_eval(connections.feeding_roads.iloc[i])\n",
    "    except ValueError:\n",
    "        connections.feeding_roads.iloc[i] = np.nan\n",
    "\n",
    "# node connections\n",
    "nodes = connections[\"Unnamed: 0\"]\n",
    "roads = connections.feeding_roads\n",
    "\n",
    "# replace nans with 0's\n",
    "connections.feeding_roads = connections.feeding_roads.fillna(0)\n",
    "\n",
    "# loop thru and establish edges\n",
    "edge_list = []\n",
    "for row in range(len(roads)):\n",
    "    node1 = connections[\"Unnamed: 0\"].iloc[row]\n",
    "    node2 = connections.feeding_roads.iloc[row]\n",
    "    try:\n",
    "        for i in range(len(node2)):\n",
    "            edge_list.append([node2[i], node1])\n",
    "        #node2 = connections.feeding_roads.iloc[row]\n",
    "    except TypeError:\n",
    "        edge_list.append([node2, node1])\n",
    "        \n",
    "# remove 0's\n",
    "edges = []\n",
    "for edge in edge_list:\n",
    "    if edge[0]==0:\n",
    "        pass\n",
    "    else:\n",
    "        edges.append(edge)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the graph\n",
    "G = nx.Graph()\n",
    "for i in range(len(nodes)):\n",
    "    G.add_node(nodes[i],spd=sp[:,i])\n",
    "    #G.add_edge(nodes[i])\n",
    "#G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adjacency matrix \n",
    "A = nx.to_numpy_array(G)\n",
    "\n",
    "# convert graph to stellargraph object for modeling\n",
    "square = StellarGraph.from_networkx(G,node_features=\"spd\")\n",
    "\n",
    "# get feature matrix\n",
    "X = square.node_features()\n",
    "#X = sp.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-links",
   "metadata": {},
   "source": [
    "# Modeling: GCN_LSTM\n",
    "\n",
    "###### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training rate\n",
    "train_rate = 0.8\n",
    "\n",
    "# replace missing values with nans\n",
    "X = np.where(X<0,0,X)\n",
    "\n",
    "# split train/test\n",
    "train_data, test_data = preprocessing.train_test_split(X, train_rate)\n",
    "\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-breeding",
   "metadata": {},
   "source": [
    "###### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data based on max/min\n",
    "train_scaled, test_scaled = preprocessing.scale_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-short",
   "metadata": {},
   "source": [
    "###### Pre-process data based on sequence and prediction length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of timesteps up to the prediction that we will feed to the model (5-minute intervals)\n",
    "seq_len = 12\n",
    "\n",
    "# the amount of time in advance we want to predict (5-minute intervals)\n",
    "pre_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, testX, testY = preprocessing.sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-metropolitan",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## 5-min sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-providence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=A,\n",
    "    gc_layer_sizes=[10],\n",
    "    gc_activations=[\"linear\"],\n",
    "    lstm_layer_sizes=[200],\n",
    "    lstm_activations=[\"linear\"],\n",
    "    dropout=0.0,\n",
    ")\n",
    "# model architecture with keras\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model_tgcn = Model(inputs=x_input, outputs=x_output)\n",
    "\n",
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model_tgcn.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "history = model_tgcn.fit(\n",
    "    x=trainX,\n",
    "    y=trainY,\n",
    "    epochs=75,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(testX,testY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-mileage",
   "metadata": {},
   "source": [
    "## Save Model Weights (T-GCN: 5-min prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to folder\n",
    "#model_tgcn.save('modeling/models/tgcn-5min')\n",
    "\n",
    "\n",
    "# load the model from disk\n",
    "#import keras\n",
    "#model_tgcn = keras.models.load_model('modeling/models/tgcn-5min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-amendment",
   "metadata": {},
   "source": [
    "## 15-min sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of timesteps up to the prediction that we will feed to the model (5-minute intervals)\n",
    "seq_len = 12\n",
    "\n",
    "# the amount of time in advance we want to predict (5-minute intervals)\n",
    "pre_len = 3\n",
    "\n",
    "trainX, trainY, testX, testY = preprocessing.sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=A,\n",
    "    gc_layer_sizes=[15],\n",
    "    gc_activations=[\"linear\"],\n",
    "    lstm_layer_sizes=[200],\n",
    "    lstm_activations=[\"linear\"],\n",
    "    dropout=0.1,\n",
    ")\n",
    "# model architecture with keras\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model_tgcn_15 = Model(inputs=x_input, outputs=x_output)\n",
    "\n",
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model_tgcn_15.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "history_15 = model_tgcn_15.fit(\n",
    "    x=trainX,\n",
    "    y=trainY,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(testX,testY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to folder\n",
    "model_tgcn_15.save('modeling/models/tgcn-15min')\n",
    "\n",
    "\n",
    "# load the model from disk\n",
    "#import keras\n",
    "#model = keras.models.load_model('modeling/models/lstm-5min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-birmingham",
   "metadata": {},
   "source": [
    "## 30-min sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of timesteps up to the prediction that we will feed to the model (5-minute intervals)\n",
    "seq_len = 12\n",
    "\n",
    "# the amount of time in advance we want to predict (5-minute intervals)\n",
    "pre_len = 6\n",
    "\n",
    "trainX, trainY, testX, testY = preprocessing.sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=A,\n",
    "    gc_layer_sizes=[15],\n",
    "    gc_activations=[\"linear\"],\n",
    "    lstm_layer_sizes=[100],\n",
    "    lstm_activations=[\"relu\"],\n",
    "    dropout=0.1,\n",
    ")\n",
    "# model architecture with keras\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model_tgcn_30 = Model(inputs=x_input, outputs=x_output)\n",
    "\n",
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model_tgcn_30.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "history_30 = model_tgcn_30.fit(\n",
    "    x=trainX,\n",
    "    y=trainY,\n",
    "    epochs=35,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(testX,testY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to folder\n",
    "model_tgcn_30.save('modeling/models/tgcn-30min')\n",
    "\n",
    "\n",
    "# load the model from disk\n",
    "#import keras\n",
    "#model = keras.models.load_model('modeling/models/lstm-5min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-vegetarian",
   "metadata": {},
   "source": [
    "## 60-min sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of timesteps up to the prediction that we will feed to the model (5-minute intervals)\n",
    "seq_len = 12*24\n",
    "\n",
    "# the amount of time in advance we want to predict (5-minute intervals)\n",
    "pre_len = 12\n",
    "\n",
    "trainX, trainY, testX, testY = preprocessing.sequence_data_preparation(\n",
    "    seq_len, pre_len, train_scaled, test_scaled\n",
    ")\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-joyce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_lstm = GCN_LSTM(\n",
    "    seq_len=seq_len,\n",
    "    adj=A,\n",
    "    gc_layer_sizes=[15],\n",
    "    gc_activations=[\"linear\"],\n",
    "    lstm_layer_sizes=[100],\n",
    "    lstm_activations=[\"relu\"],\n",
    "    dropout=0.1,\n",
    ")\n",
    "# model architecture with keras\n",
    "x_input, x_output = gcn_lstm.in_out_tensors()\n",
    "model_tgcn_60 = Model(inputs=x_input, outputs=x_output)\n",
    "\n",
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model_tgcn_60.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "history_60 = model_tgcn_60.fit(\n",
    "    x=trainX,\n",
    "    y=trainY,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(testX,testY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.utils.plot_history(history_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to folder\n",
    "#model_tgcn_60.save('modeling/models/tgcn-60min')\n",
    "\n",
    "\n",
    "# load the model from disk\n",
    "#import keras\n",
    "#model = keras.models.load_model('modeling/models/lstm-5min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
